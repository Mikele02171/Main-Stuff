{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"HYAhlNXw8ei0"},"source":["#CSE5DL Assignment\n","\n","### Assignment due date: Sunday 4 June 2023 by 11:59 pm (AEST/AEDT)\n","\n","Penalties are applied to late assignments (accepted up to 5 business days after the due date only). Five percent is deducted per business day late. A mark of zero will be assigned to assignments submitted more than 5 days late. \n","\n","<font color='red'> This is an individual assignment. You are not permitted to work as a part of a group when writing this assignment. </font>\n","\n","### Assignment submission\n","\n","Please zip all `*.ipynb`, `*.py`, `*.docx` and `*.xlsx` files into a single zip file and submit the zipped file via the link provided on LMS. \n","\n","### Copying, Plagiarism\n","Plagiarism is the submission of somebody elseâ€™s work in a manner that gives the impression that the work is your own. For individual assignments, plagiarism includes the case where two or more students work collaboratively on the assignment.  The Department of Computer Science and Information Technology treats plagiarism very seriously.  When it is detected, penalties are strictly imposed.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9yQ1TwYgWS0z"},"source":["\n","# Introduction\n","\n","**DESCRIPTION:** In this assignment we have provided you with skeleton code. You have an image dataset, and you must train a deep learning model for it. All of the code required has already been shown to you in the labs.\n","\n","In this assignment you will be required to write code and write short answer responses to questions in a structured report. You have been provided with a template Word document of this report in which you simply have to fill in the blanks (1-3 sentences is expected).\n","\n","Throughout this assignment, there are a few challenge questions worth bonus marks. There are a total of 97 marks possible before challenge questions. You can receive up to 6 marks from at most 2 challenge questions, so the maximum number of marks you can get is 103. However if you get over 100 marks the actual mark you will receive is 100% for the assignment assessment component of your grades. Unless otherwise stated all marks quoted do not include challenge questions.\n","\n","There are 61 marks associated with code, 21 marks associated with the short answer part of the report, and 15 marks associated with the experimentation part of the report.\n","\n","**INSTRUCTIONS:**\n","\n","1.   Copy the skeleton files to your Google Drive.\n","2.   Edit `SKELETON_DIR` in the first cell to point to the skeleton files you uploaded in step 1. The provided code assumes you have uploaded them to \"Uni/CSE5DL/Assignment\" in your Google Drive.\n","3.   Run the following two cells\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DI_h0wYR8WwZ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set the working directory for the assignment\n","import os\n","SKELETON_DIR = '/content/drive/MyDrive/Uni/CSE5DL/Assignment'\n","os.chdir(SKELETON_DIR)\n","! mkdir -p \"$SKELETON_DIR/saved_models\"\n","! mkdir -p \"$SKELETON_DIR/logs\"\n","\n","# Set up auto-reloading modules from the working directory\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Install extra dependencies\n","!pip install -q wandb==0.15.0\n","!pip install -q torchmetrics==0.11.3\n","\n","# Set the default figure size\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.dpi'] = 120"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McyD2WEJJDz6"},"outputs":[],"source":["%%shell\n","DATA_URL='1pgFeXWvQE-rOdYSUlHHiVSO0RVUJuuU2'\n","\n","pip install --upgrade --no-cache-dir gdown\n","pushd /content\n","gdown  $DATA_URL\n","unzip -q data.zip\n","popd"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0UMZDfCl9uzf"},"source":["# Task 1 - Image Classification\n","\n","**MARKS**: 97\n","\n","In this first task, you will create a deep learning model to classify images of skin lesions into one of seven classes: \n","\n","1.   \"MEL\" = Melanoma\n","2.   \"NV\" = Melanocytic nevus\n","3.   \"BCC\" = Basal cell carcinoma\n","4.   \"AKIEC\" = Actinic keratosis\n","5.   \"BKL\" = Benign keratosis\n","6.   \"DF\" = Dermatofibroma\n","7.   \"VASC\" = Vascular lesion\n","\n","The data for this task is a subset of: https://challenge2018.isic-archive.com/task3/\n","\n","The data for this task is inside the `/content/data/img` folder. It contains ~3,800 images named like `ISIC_000000.jpg` and the following label files:\n","\n","*   `/content/data/img/train.csv`\n","*   `/content/data/img/val.csv`\n","*   `/content/data/img/train_small.csv`\n","*   `/content/data/img/val_small.csv`\n","\n","The `small` versions are the first 200 lines of each partition and are included for debugging purposes. To save time, ensure your code runs on the `small` versions first.\n","\n","**NOTE**: To explore the labels, you can click the above hyperlinks to open the relevant csv file."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VXe_oJsh2v0R"},"source":["## Task 1a. Explore the training set\n","\n","**MARKS**: 8 (Code 6, Reports 2)\n","\n","**INSTRUCTIONS**: Check for data issues, as we have done in the labs. Check the class distribution and at least 1 other potential data issue. Hint: Look in `explore.py` for a function that can plot the class distribution.\n","\n","**REPORT**: What did you check for? What data issues are present in this dataset?\n","\n","**HINT**: This task primarily requires \"PyTorch Basics\" lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvZcHWR_nrN_"},"outputs":[],"source":["import pandas as pd\n","\n","IMG_CLASS_NAMES = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n","\n","train_df = pd.read_csv('/content/data/img/train.csv')\n","val_df = pd.read_csv('/content/data/img/val.csv')\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpqxCqPth8va"},"outputs":[],"source":["from PIL import Image\n","# Change the filename to view other examples from the dataset \n","display(Image.open('/content/data/img/ISIC_0024306.jpg'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J6nJ9TKkDM_E"},"outputs":[],"source":["import explore\n","\n","# TODO - Check for data issues\n","# Hint: You can convert from one-hot to integers with argmax\n","#       This way you can convert 1, 0, 0, 0, 0, 0, 0  to class 0 \n","#                                0, 1, 0, 0, 0, 0, 0  to class 1\n","#                                0, 0, 1, 0, 0, 0, 0  to class 2\n","# so it should be something like the following: \n","# train_labels = train_df.values[....].argmax(....)\n","# val_labels = val_df.values[....].argmax(....)\n","#     - you need to fill in the ... parts with the correct values.\n","# You should then print output the contents of train_labels to see if \n","# it matches the contents of train.csv\n","#\n","# Next you can plot the class distributions like the following:\n","# explore.plot_label_distribution(....)\n","#    - do the above for both the train and val labels.\n","#\n","# Following this look for other potential problems with the data\n","#   You can look at lab 2a to see what was checked there.\n","#   You may also think of any other potential problems with the data.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EzxriiNQ22CG"},"source":["## Task 1b. Implement Training loop\n","\n","**MARKS**: 22 (Code 20, Reports 2)\n","\n","**INSTRUCTIONS**:\n","\n","*   Implement LesionDataset in `datasets.py`. Use the cell below to test your implementation. \n","*   Implement the incomplete functions in `train.py` marked as \"Task 1b\"\n","*   Go to the [Model Training Cell](#task-1-model-training) at the end of Task 1 and fill in the required code for \"Task 1b\".\n","\n","**REPORT**: Why should you *not use* `random_split` in your code here?\n","\n","**HINT**: This task primarily requires \"PyTorch Basics\" lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uZTyqK9XvsJ"},"outputs":[],"source":["import datasets\n","\n","ds = datasets.LesionDataset('/content/data/img',\n","                            '/content/data/img/train.csv')\n","input, label = ds[0]\n","print(input)\n","print(label)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dg_P1_Pd26Bm"},"source":["## Task 1c. Implement a baseline convolutional neural network\n","\n","**MARKS**: 25 (Code 18, Reports 7)\n","\n","You will implement a baseline convolutional neural network which you can compare results to. This allows you to evaluate any improvements made by hyperparameter tuning or transfer learning.\n","\n","**INSTRUCTIONS**:\n","\n","*   Implement a `SimpleBNConv` in `models.py` with:\n","    *   5 `nn.Conv2d` layers, with 8, 16, 32, 64, 128 output channels respectively, with the following between each convolution layer:\n","        *   `nn.ReLU()` for the activation function, and\n","        *   `nn.BatchNorm2d`, and\n","        *   finally a `nn.MaxPool2d` to downsample by a factor of 2.\n","*   Use a normalised confusion matrix on the model's validation predictions in `train.py`.\n","*  Go to the [Model Training Cell](#task-1-model-training) at the end of Task 1 and fill in the required code to train the model.\n","\n","Training should take about 1 minute/epoch. Validation accuracy should be 60-70%, but UAR should be around 20-40%.\n","\n","**REPORT**: As training sets get larger, the length of time per epoch also gets larger. Some datasets take over an hour per epoch. This makes it impractical to debug typos in your code since it can take hours after starting for the program to reach new code. Name two ways to significantly reduce how long **each** epoch takes - for debugging purposes - while still using real data and using the real training code.\n","\n","**REPORT**: Show the confusion matrix and plots of the validation accuracy and UAR in your report, and explain what is going wrong. \n","(Right-click a plot and select \"save image as...\" to save the image to your computer)\n","\n","**HINT**: This task primarily requires \"Convolutional Neural Networks\" lab."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bnlbHlO953Dw"},"source":["## Task 1d. Account for data issues\n","\n","**MARKS**: 12 (Code 8, Reports 4)\n","\n","**INSTRUCTIONS**: Account for the data issues in Task 1a and retrain your model.\n","\n","**REPORT**: How did you account for the data issues? Was it effective? How can you tell? Show another confusion matrix.\n","\n","**IMPORTANT NOTE**: One of the techniques from the lab will cause a warning in the metric calculation on `train_small.csv`, but will work fine on `train.csv`.\n","\n","**HINT**: This task primarily requires \"Debugging Neural Networks\" lab."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z4bd8vMQ3C6b"},"source":["## Task 1e. Data Augmentation\n","\n","**MARKS**: 10 (Code 4, Reports 6)\n","\n","**INSTRUCTIONS**: \n","\n","*   Add an `augment` flag to LesionDataset which specifies whether any augmentation is done to the images. Ensure it is set to `True` *only* for the training dataset.\n","*   Use random horizontal flips\n","*   Use at least 2 other different non-deterministic augmentations\n","\n","**REPORT:** Are random vertical flips appropriate for this dataset? Why?\n","\n","Using data augmentation does not guarantee improved model performance. Data augmentation can hurt test performance by making the model train on unrealistic images.\n","\n","**REPORT**: What effect did Data Augmentation have on performance? Show a screenshot of the relevant graphs from Weights & Biases for evidence.\n","\n","**CHALLENGE**: (3 marks) Apply 5 crop augmentation with crop size 200x300. Make a distinct model which uses 5 crops at once to give a single answer. Include in your report how you did this and report the effect on performance.\n","\n","**HINT**: This task primarily requires \"Image Augmentation\" lab."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3DkP5Mg48Gm1"},"source":["## Task 1f. Chase improved performance\n","\n","**MARKS**: 20 (Code and reports)\n","\n","**INSTRUCTIONS**: \n","*   Create a model from a pre-trained model from the torchvision model zoo. We recommend Resnet18, but you may use any model you like. You may freeze the weights of all layers except the last, or fine-tune all the weights. https://drive.google.com/file/d/12Bq-00qRNTBxzGZ9X_iqWndluB5hmuG1/view?usp=share_link\n","*   Create your own models, modifying the model architecture, try different losses, learning rates. Change anything you like except the evaluation metrics in search of a better model.\n","\n","Train at least 10 different models, each with a different combination.\n","\n","**REPORT**: Create a table in an excel spreadsheet that is similar to that used in Lab 3 to record your results. Make sure it includes every parameter of variation between your combinations as a separate column. Include notes about what you were thinking/hoping for each combination as a number column in the spreadsheet.\n","\n","In addition to the excel spreadsheet generate a report using Weights and Biases of the models you trained and the performance curves. Save the report as a pdf and include this in your submission. Please see this link on how to generate reports with Weights and Biases. https://docs.wandb.ai/guides/reports\n","\n","Play around with Weights and Biases to see what cool features you can dig out and use to better visualize the training results and use that to improve the information shared via the report. \n","\n","**Important**: Write a discussion about the key findings from the experimental results. What worked? What didn't? You don't need to be correct, you just need to put forward a coherent and consistent argument based on your observed results.\n","\n","**CHALLENGE REPORT**: (3 marks) Assuming you use the full dataset in a single epoch, if you halve the size of the batch size, what happens to the number of times that you update the weights per epoch? With reference to the gradients, under what circumstances is this good?\n","\n","**HINT**: The first part of this task primarily requires \"Transfer Learning\" lab."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RxhIzDQjt4mu"},"source":["<a name=\"task-1-model-training\"></a>\n","## Model Training Cell\n","\n","We will be using Weights and Biases to keep track of our experimental runs and evaluation metrics. The Weights and Biases tool is only used in \"Text Sentiment Analysis\" lab. If you have not completed this lab yet, you can get started with Weights and Biases by following Steps 1a), b) and c) from the following link: https://docs.wandb.ai/quickstart\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tFG3cT2i53Q"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import WeightedRandomSampler\n","\n","import datasets\n","import models\n","import train\n","\n","torch.manual_seed(42)\n","\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 64\n","\n","# Create datasets/loaders\n","# TODO Task 1b - Create the data loaders from LesionDatasets\n","# TODO Task 1d - Account for data issues, if applicable\n","# train_dataset = ...\n","# val_dataset = ...\n","# train_loader = ...\n","# val_loader = ...\n","\n","# Instantiate model, optimizer and criterion\n","# TODO Task 1c - Make an instance of your model\n","# TODO Task 1d - Account for data issues, if applicable\n","# model = ...\n","\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train model\n","# TODO Task 1c: Set ident_str to a string that identifies this particular\n","#               training run. Note this line in the training code\n","#                     exp_name = f\"{model.__class__.__name__}_{ident_str}\"\n","#               So it means the the model class name is already included in the\n","#               exp_name string. You can consider adding other information \n","#               particular to this training run, e.g. learning rate (lr) used, \n","#               augmentation (aug) used or not, etc.\n","\n","train.train_model(model, train_loader, val_loader, optimizer, criterion,\n","                  IMG_CLASS_NAMES, NUM_EPOCHS, project_name=\"CSE5DL Assignment Task 1\",\n","                  ident_str= \"fill me in here\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
