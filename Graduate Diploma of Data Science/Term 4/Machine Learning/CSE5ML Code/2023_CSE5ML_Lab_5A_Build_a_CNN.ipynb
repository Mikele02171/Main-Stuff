{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE5ML Lab 5A: Build a Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create a simple CNN\n",
    "\n",
    "When we build a Convolutional Neural Network model, we would need to have convolutional layers, max pooling and dense layers. To enhance the performance, we would also include dropouts. Bellow is a Simple CNN model for the CIFAR-10 Dataset.\n",
    "\n",
    "Dropout is a regularization method proposed by Srivastava, et al at 2014. It is a  simple yet effective way to Prevent Neural Networks from Overfitting. Dropout randomly selectes percentage of neurons and ignore them during training. This means that their contribution to the activation is temporally removed on the forward pass, and any weight updates are not applied to the neuron on the backward pass.\n",
    "\n",
    "### Load dataset and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load data\n",
    "(Inputs, Labels), (Test_Data, Test_Label) = cifar10.load_data() # notice the first line of importing packages\n",
    "#Check the shape of the data\n",
    "\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "# Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n",
    "Inputs = Inputs.astype('float32')\n",
    "Test_Data = Test_Data.astype('float32')\n",
    "Inputs = Inputs / 255.0\n",
    "Test_Data = Test_Data / 255.0\n",
    "\n",
    "# Encode the outputs with one hot coding\n",
    "Labels = np_utils.to_categorical(Labels) #Converts a class vector (integers) to binary class matrix.\n",
    "Test_Label = np_utils.to_categorical(Test_Label)\n",
    "num_classes = Test_Label.shape[1]\n",
    "\n",
    "print(Inputs.shape)\n",
    "print(Labels.shape)\n",
    "print(Test_Data.shape)\n",
    "print(Test_Label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a convolutional neural networks model\n",
    "\n",
    "More information about parameters settings in Conv2D can be found here: https://keras.io/api/layers/convolution_layers/convolution2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "define loss function, optimizer and addtional evaluation metrics\n",
    "\n",
    "#### Some addtional information about optimizers\n",
    "\n",
    "To undrestand the concept of optimizers one usually begins with the most basic and popular one, Gradient Descent (used in the bellow example). The important part of the Gradient Descent algorithm (and optimizers in general) is to understand gradients, which indicates: what a small change in a a given parameter (here weight) would do to the loss function. Gradients are a measure of change. They are the connection between the loss function and the weights. In a simple language, they tell us what specific operation should be performed to the weights (ezamples: add 2.1, subtract .07, etc.), for the purpose of reducing the loss (which will increase the accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "lrate = 0.002\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the model\n",
    "it can help us understand model structure, the shape of output and the number of parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,210,090\n",
      "Trainable params: 4,210,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "834/834 [==============================] - 60s 70ms/step - loss: 1.9910 - accuracy: 0.2874 - val_loss: 1.8193 - val_accuracy: 0.3615\n",
      "Epoch 2/5\n",
      "834/834 [==============================] - 59s 71ms/step - loss: 1.7683 - accuracy: 0.3783 - val_loss: 1.6809 - val_accuracy: 0.4138\n",
      "Epoch 3/5\n",
      "834/834 [==============================] - 59s 71ms/step - loss: 1.6594 - accuracy: 0.4178 - val_loss: 1.5902 - val_accuracy: 0.4410\n",
      "Epoch 4/5\n",
      "834/834 [==============================] - 58s 69ms/step - loss: 1.5905 - accuracy: 0.4395 - val_loss: 1.5506 - val_accuracy: 0.4566\n",
      "Epoch 5/5\n",
      "834/834 [==============================] - 60s 72ms/step - loss: 1.5382 - accuracy: 0.4580 - val_loss: 1.4905 - val_accuracy: 0.4751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206035bc4c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(Inputs, Labels, validation_data=(Test_Data, Test_Label), epochs=epochs, batch_size=60, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model with testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.51%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(Test_Data, Test_Label, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper CNN network and optimization\n",
    "We can add more layers to have a more complex model. Bellow is an example of a deeper CNN model for the CIFAR-10 Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,915,114\n",
      "Trainable params: 2,915,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikel\\anaconda3\\envs\\p\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 191s 242ms/step - loss: 2.2115 - accuracy: 0.1717 - val_loss: 1.9698 - val_accuracy: 0.2697\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 189s 242ms/step - loss: 1.8895 - accuracy: 0.3128 - val_loss: 1.7449 - val_accuracy: 0.3793\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 188s 241ms/step - loss: 1.6385 - accuracy: 0.4081 - val_loss: 1.5191 - val_accuracy: 0.4546\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 188s 240ms/step - loss: 1.4964 - accuracy: 0.4586 - val_loss: 1.4104 - val_accuracy: 0.4923\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.4043 - accuracy: 0.4958 - val_loss: 1.3743 - val_accuracy: 0.5045\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 188s 240ms/step - loss: 1.3358 - accuracy: 0.5226 - val_loss: 1.2763 - val_accuracy: 0.5399\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 187s 239ms/step - loss: 1.2607 - accuracy: 0.5514 - val_loss: 1.2257 - val_accuracy: 0.5606\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 188s 241ms/step - loss: 1.1965 - accuracy: 0.5738 - val_loss: 1.2148 - val_accuracy: 0.5679\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 189s 241ms/step - loss: 1.1363 - accuracy: 0.5963 - val_loss: 1.1454 - val_accuracy: 0.5971\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 190s 243ms/step - loss: 1.0831 - accuracy: 0.6181 - val_loss: 1.1301 - val_accuracy: 0.5992\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 338s 433ms/step - loss: 1.0315 - accuracy: 0.6362 - val_loss: 1.0648 - val_accuracy: 0.6239\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 427s 547ms/step - loss: 0.9776 - accuracy: 0.6529 - val_loss: 1.0366 - val_accuracy: 0.6333\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 305s 389ms/step - loss: 0.9278 - accuracy: 0.6743 - val_loss: 1.0196 - val_accuracy: 0.6414\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 3394s 4s/step - loss: 0.8840 - accuracy: 0.6882 - val_loss: 0.9920 - val_accuracy: 0.6524\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 192s 245ms/step - loss: 0.8462 - accuracy: 0.7029 - val_loss: 0.9675 - val_accuracy: 0.6630\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 182s 233ms/step - loss: 0.7944 - accuracy: 0.7209 - val_loss: 0.9663 - val_accuracy: 0.6675\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 181s 232ms/step - loss: 0.7538 - accuracy: 0.7345 - val_loss: 0.9494 - val_accuracy: 0.6693\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 184s 235ms/step - loss: 0.7084 - accuracy: 0.7493 - val_loss: 0.9697 - val_accuracy: 0.6683\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 314s 402ms/step - loss: 0.6683 - accuracy: 0.7664 - val_loss: 0.9670 - val_accuracy: 0.6725\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 419s 535ms/step - loss: 0.6280 - accuracy: 0.7804 - val_loss: 0.9395 - val_accuracy: 0.6834\n",
      "Accuracy: 68.34%\n"
     ]
    }
   ],
   "source": [
    "# Pakages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# load data\n",
    "(Inputs, Labels), (Test_Data, Test_Label) = cifar10.load_data()\n",
    "# normalize inputs (so all pixel values are transformed from [0,255] to [0,0-1.0]\n",
    "Inputs = Inputs.astype('float32')\n",
    "Test_Data = Test_Data.astype('float32')\n",
    "Inputs = Inputs / 255.0\n",
    "Test_Data = Test_Data / 255.0\n",
    "# Encode outputs\n",
    "Labels = np_utils.to_categorical(Labels)\n",
    "Test_Label = np_utils.to_categorical(Test_Label)\n",
    "num_classes = Test_Label.shape[1]\n",
    "\n",
    "#Print out the shapes\n",
    "print(Inputs.shape)\n",
    "print(Labels.shape)\n",
    "print(Test_Data.shape)\n",
    "print(Test_Label.shape)\n",
    "\n",
    "# Build a deeper CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 20\n",
    "lrate = 0.001\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Fit the model\n",
    "model.fit(Inputs, Labels, validation_data=(Test_Data, Test_Label), epochs=epochs, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(Test_Data, Test_Label, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Some popular network network structures for image classification and load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet, ResNet, Inception, and Xception are four types popular neural networks that are proven to be effective in image classification tasks. In keras, there are five popular model structures, namely VGG16, VGG19, ResNet50, Inception V3 and Xception; you can train these models from scratch with newly initialized weights, or you can load pretrained model, based on the ImageNet dataset (another popular benchmark dataset in image classification, which is even larger than the CIFAR10 dataset, with a size of 224*224 for each image). Sometimes we find the pretrained model very helpful when the input data is similar and we do not want to use a lot of time to retrain the model from scratch.\n",
    "\n",
    "If you are interested in more information about these models and implementation with Keras, you can check this link: https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "\n",
    "Here we use VGG16 as an example. The same steps can be applied in other models.\n",
    "\n",
    "The below attached is the model achitecture for the original VGG16: \n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "\n",
    "    # Classification block\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a pre-defined network structure for a task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load data\n",
    "(Inputs, Labels), (Test_Data, Test_Label) = cifar10.load_data() # notice the first line of importing packages\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "# Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n",
    "Inputs = Inputs.astype('float32')\n",
    "Test_Data = Test_Data.astype('float32')\n",
    "Inputs = Inputs / 255.0\n",
    "Test_Data = Test_Data / 255.0\n",
    "\n",
    "# Encode the outputs with one hot coding\n",
    "Labels = np_utils.to_categorical(Labels) #Converts a class vector (integers) to binary class matrix.\n",
    "Test_Label = np_utils.to_categorical(Test_Label)\n",
    "num_classes = Test_Label.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "Here we give two ways to load the model structure and train the model on CIFAR10 dataset. First, if you do not care about how much time or resources to use on trainig, you can train the model from scratch with newly intialized weights. Another way is to train the model based some pretrained weights on similar datasets (because it is found that the first few layers trained for different dataset basically do the similar things, and this's the reason we can consider adopt the weights trained from other dataset, and further fine-tune the weights on our dataset). This can accelate training with fewer epochs/iterations. \n",
    "\n",
    "Note: when apply the below codes, you may find your computer resources can not really support you running them, and here I just show you how you can load a pretrained model weights which has been trained on CIFAR10 already, and you can see how this complex neural network structure can improve classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train model from scratch\n",
    "\n",
    "# load vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load the model\n",
    "model = VGG16(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 10s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model and finetune\n",
    "# Note that we drop the 3 fully-connected layers at the top of the network which mainly act like classifiers to classify the extracted features from the convolutional layers, because we have a new dataset and we want to train a new classifier.\n",
    "\n",
    "# load vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load the model\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,786,890\n",
      "Trainable params: 2,786,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model which has been finetuned on CIFAR10, not that this model has only used the first 3 blocks in the VGG16 model\n",
    "# load vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "#from keras.engine import Model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# load the model\n",
    "model = VGG16(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "# Extract the last layer from third block of vgg16 model\n",
    "last = model.get_layer('block3_pool').output\n",
    "# Add classification layers on top of it\n",
    "x = Flatten()(last)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "pred = Dense(10, activation='softmax')(x)\n",
    "model = Model(model.input, pred)\n",
    "\n",
    "# load pretrained weigths\n",
    "model.load_weights('cifar10-vgg16_model.h5')\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "This will take some time because of the large model and big amount of data. Since we already loaded the trained weights with `model.load_weights('cifar10-vgg16_model.h5')`you do not need to train it again using the below code. This is just for your information of how you can train or further fine-tune a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 254s 160ms/step - loss: 1.2623 - accuracy: 0.5677 - val_loss: 0.7724 - val_accuracy: 0.7400\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 261s 167ms/step - loss: 0.7829 - accuracy: 0.7377 - val_loss: 0.7159 - val_accuracy: 0.7564\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 250s 160ms/step - loss: 0.6621 - accuracy: 0.7791 - val_loss: 0.6535 - val_accuracy: 0.7857\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 248s 159ms/step - loss: 0.5798 - accuracy: 0.8047 - val_loss: 0.7161 - val_accuracy: 0.7686\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 0.5197 - accuracy: 0.8253 - val_loss: 0.6381 - val_accuracy: 0.7940\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 288s 184ms/step - loss: 0.4743 - accuracy: 0.8422 - val_loss: 0.6382 - val_accuracy: 0.7931\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 230s 147ms/step - loss: 0.4385 - accuracy: 0.8500 - val_loss: 0.6719 - val_accuracy: 0.7968\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.4088 - accuracy: 0.8631 - val_loss: 0.6603 - val_accuracy: 0.7990\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 248s 159ms/step - loss: 0.3890 - accuracy: 0.8706 - val_loss: 0.7108 - val_accuracy: 0.7918\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 250s 160ms/step - loss: 0.3759 - accuracy: 0.8757 - val_loss: 0.7343 - val_accuracy: 0.7876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2063043bc10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 10\n",
    "# Fit the model\n",
    "model.fit(Inputs, Labels, validation_data=(Test_Data, Test_Label), epochs=epochs, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can save the model weight to use it next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cifar10_vgg16_new_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.76%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(Test_Data, Test_Label, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
