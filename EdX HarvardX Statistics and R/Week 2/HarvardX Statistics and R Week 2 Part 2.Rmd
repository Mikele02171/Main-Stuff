---
title: "Untitled"
output: word_document
---



```{r}
library(downloader) 
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleControlsPopulation.csv"
filename <- basename(url)
download(url, destfile=filename)
x <- unlist( read.csv(filename) )
```

#Question 1 
```{r}
set.seed(1)
n = 1000
null <- vector("numeric",n)

#From the solution 
for (i in 1:n) {
  X <- sample(x,5)
  n[i] <- mean(X)
}

hist(n)
mean(abs(n-mean(x))>1) 
#0.503

```



#Question 2

```{r}

set.seed(1)
n = 10000
null <- vector("numeric",n)
for (i in 1:n) {
  X <- sample(x,5)
  n[i] <- mean(X)
}

hist(n)
mean(abs(n-mean(x))>1) 
#0.503


```

#Probability Distributions Exercises 

#Question 1 

```{r}

library(gapminder)
data(gapminder)
head(gapminder)

```


```{r}
#Actual solution

dat1952 = gapminder[gapminder$year == 1952, ] #help select the column (year) and element (1952) respectively as our new dataset (dat1952). 

x = dat1952$lifeExp #Take the column of our new dataset (dat1952).
mean(x <= 40)

```

#Normal Distribution Exercises #1
#Use a histogram to "look" at the distribution of averages we get with a sample size of 5 and a sample size of 50. How would you say they differ?


They both look roughly normal, but with a sample size of 50 the spread is smaller.



```{r}
# make averages5
set.seed(1)
n <- 1000
averages5 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(x,5)
  averages5[i] <- mean(X)
}

# make averages50
set.seed(1)
n <- 1000
averages50 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(x,50)
  averages50[i] <- mean(X)
}


```


#Normal Distribution Exercises #2
#For the last set of averages, the ones obtained from a sample size of 50, what proportion are between 23 and 25?

```{r}
# make averages50
set.seed(1)
n <- 1000
averages50 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(x,50)
  averages50[i] <- mean(X)
}

pnorm(25, mean(averages50), sd = 1) 
pnorm(23, mean(averages50), sd = 1)
#0.99 Final Answer

#Actual Method

 mean( averages50 < 25 & averages50 > 23) #Gives me 0
 
```
#Normal Distribution Exercises #3
#Note that you can use the function pnorm() to find the proportion of observations below a cutoff x given a normal distribution with mean mu and standard deviation sigma with pnorm(x, mu, sigma) or pnorm( (x-mu)/sigma ).

#What is the proportion of observations between 23 and 25 in a normal distribution with average 23.9 and standard deviation 0.43?
```{r}

pnorm( 25 ,mean = 23.9, sd = 0.43)
pnorm( 23 ,mean = 23.9, sd = 0.43)


pnorm( 25 ,mean = 23.9, sd = 0.43)-pnorm( 23 ,mean = 23.9, sd = 0.43)
 #0.9765648
```

#Population, Samples, and Estimates Exercises

```{r}
library(downloader) 
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- read.csv(filename) 
```


#Remove the lines that contain missing values
```{r}
dat <- na.omit(dat)

```



#Population, Samples, and Estimates Exercises #1
#1 point possible (graded)
#Use dplyr to create a vector x with the body weight of all males on the control (chow) diet.

#What is this population's average?



```{r}
library(dplyr)
df = dat[dat$Sex == 'M'& dat$Diet == "chow",]
x = df$Bodyweight
mean(x) #30.96381

```


#Population, Samples, and Estimates Exercises #2
#1 point possible (graded)
#Now use the rafalib package and use the popsd() function to 
#compute the population standard deviation.

```{r}
library(rafalib)
popsd(x)
 #4.420501
```
#Population, Samples, and Estimates Exercises #3
#Set the seed at 1. Take a random sample X of size 25 from x.
#What is the sample average?

```{r}
set.seed(1)
n <- 25
averages25 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(x,25)
  averages25[i] <- mean(X)
}

mean(averages25) #30.77248


#Solution        
set.seed(1)
X <- sample(x,25)
mean(X) #30.5196


```


#Population, Samples, and Estimates Exercises #4
#Use dplyr to create a vector y with the body weight of all males on the high fat hf) diet.

#What is this population's average?
```{r}
library(dplyr)
df2 = dat[dat$Sex == 'M'& dat$Diet == "hf",]
y = df2$Bodyweight
mean(y) 

```
#Population, Samples, and Estimates Exercises #5
#1 point possible (graded)
#Now use the rafalib package and use the popsd() function to compute the population standard deviation.
```{r}
library(dplyr)
library(rafalib)
popsd(y)
 #5.574609
```


#Population, Samples, and Estimates Exercises #6
#1 point possible (graded)
#Set the seed at 1. Take a random sample  of size 25 from y.

#What is the sample average?
```{r}
set.seed(1)
Y <- sample(y,25)
mean(Y) #35.8036
```
#Population, Samples, and Estimates Exercises #7
#1 point possible (graded)
#What is the difference in absolute value between y.bar-x.bar and Y.bar-X.bar?
```{r}
d1 = mean(x)-mean(y)
d2 = mean(X)-mean(Y)

d1-d2 #1.399884

```
#Population, Samples, and Estimates Exercises #8
#Repeat the above for females, this time setting the seed to 2.
#1 point possible (graded)
#What is the difference in absolute value between y.bar-x.bar and Y.bar-X.bar?

```{r}
library(dplyr)
df3 = dat[dat$Sex == 'F'& dat$Diet == "chow",]
x1 = df3$Bodyweight
mean(x1) #23.89338

set.seed(2)
X <- sample(x1,25)
mean(X) #23.8684

df4 = dat[dat$Sex == 'F'& dat$Diet == "hf",]
y1 = df4$Bodyweight
mean(y1) #26.2689

set.seed(2)
Y <- sample(y1,25)
mean(Y) #25.8792


d11 = mean(x1) - mean(y1)
d12 = mean(X) - mean(Y)
d11-d12 #0.3647172

```

#Central Limit Theorem Exercises
#Central Limit Theorem Exercises #1
#If a list of numbers has a distribution that is well approximated by the normal distribution, what proportion of these numbers are within one standard deviation away from the list's average?
```{r}
library(downloader) 
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url, destfile=filename)
dat1 <- na.omit( read.csv(filename) )
```
```{r}
dat1

```


```{r}


pnorm(1)-pnorm(-1)
#Solution 0.6826895 (Got this wrong)

```

#Central Limit Theorem Exercises #2
#1 point possible (graded)
#What proportion of these numbers are within two standard deviations away from the list's average?

```{r}
pnorm(2)-pnorm(-2)
#Solution  0.9544997

```
#Central Limit Theorem Exercises #3
#1/1 point (graded)
#What proportion of these numbers are within three standard deviations away from the list's average?
```{r}
pnorm(3)-pnorm(-3)
#Solution  0.9973002

```
#Central Limit Theorem Exercises #4
#1 point possible (graded)
#Define y to be the weights of males on the control diet.

#What proportion of the mice are within one standard deviation away from the average weight?
#Remember to use popsd() from rafalib for the population standard deviation.
```{r}
y = dat[dat$Sex == 'M',]
maleweights = y$Bodyweight
library(rafalib)
popsd(maleweights) #5.352063
mean(maleweights) #32.76582


pnorm(5.352063)-(1-pnorm(-5.352063))

#Actual solution
a = dat[dat$Sex == 'M' & dat$Diet == 'chow',]
y = a$Bodyweight
z <- ( y - mean(y) ) / popsd(y)
mean( abs(z) <=1 ) #0.6950673

```
#Central Limit Theorem Exercises #5
#1 point possible (graded)
#What proportion of these numbers are within two standard deviations away from the list's average?
```{r}
mean( abs(z) <=2 )  #0.9461883

```
#Central Limit Theorem Exercises #6
#1 point possible (graded)
#What proportion of these numbers are within three standard deviations away from the list's average?
```{r}
mean( abs(z) <=3 )  #0.9910314

```


#Central Limit Theorem Exercises #7
#1 point possible (graded)
#Which of the following best describes the qq-plot comparing mouse weights to the normal distribution?

Solution: The mouse weights are well approximated by the normal distribution, although the larger values (right tail) are larger than predicted by the normal. This is consistent with the differences seen between question 3 and 6.

#Central Limit Theorem Exercises #8
#1 point possible (graded)
#Here we are going to use the function replicate() to learn about the distribution of random variables. All the above exercises relate to the normal distribution as an approximation of the distribution of a fixed list of numbers or a population. We have not yet discussed probability in these exercises. If the distribution of a list of numbers is approximately normal, then if we pick a number at random from this distribution, it will follow a normal distribution. However, it is important to remember that stating that some quantity has a distribution does not necessarily imply this quantity is random. Also, keep in mind that this is not related to the central limit theorem. The central limit applies to averages of random variables. Let's explore this concept.

#We will now take a sample of size 25 from the population of males on the chow diet. The average of this sample is our random variable. We will use the replicate() function to observe 10,000 realizations of this random variable. Set the seed at 1, then generate these 10,000 averages. Make a histogram and qq-plot of these 10,000 numbers against the normal distribution.

#We can see that, as predicted by the CLT, the distribution of the random variable is very well approximated by the normal distribution.

```{r}
df <- dat[dat$Sex=="M" & dat$Diet=="chow",]
y=df$Bodyweight 
set.seed(1)
avgs <- replicate(10000, mean( sample(y, 25)))
mypar(1,2)
hist(avgs)
qqnorm(avgs)
qqline(avgs)

```

```{r}
mean(avgs) #30.96856

```

#Central Limit Theorem Exercises #9
#1 point possible (graded)
#What is the standard deviation of the distribution of sample averages (use popsd())?
```{r}
popsd(avgs) #0.827082

```

#CLT and t-distribution in Practice Exercises #1
```{r}
#Use for Excerises 3-13
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleMiceWeights.csv"
filename <- "femaleMiceWeights.csv"
if(!file.exists("femaleMiceWeights.csv")) download(url,destfile=filename)
dat <- read.csv(filename)

```


#Actual solution
```{r}
set.seed(1)
n <- 100
sides <- 6
p <- 1/sides
zs <- replicate(10000,{
  x <- sample(1:sides,n,replace=TRUE)
  (mean(x==6) - p) / sqrt(p*(1-p)/n)
}) 
qqnorm(zs)
abline(0,1)#confirm it's well approximated with normal distribution
mean(abs(zs) > 2) #0.0431
```


#CLT and t-distribution in Practice Exercises #2
#For the last simulation you can make a qqplot to confirm the normal approximation. Now, the CLT is an asymptotic result, meaning it is closer and closer to being a perfect approximation as the sample size increases. In practice, however, we need to decide if it is appropriate for actual sample sizes. Is 10 enough? 15? 30?

#In the example used in exercise 1, the original data is binary (either 6 or not). In this case, the success probability also affects the appropriateness of the CLT. With very low probabilities, we need larger sample sizes for the CLT to "kick in".

#Run the simulation from exercise 1, but for different values of p and n. For which of the following is the normal approximation best?


Solution: p=0.5 and n=5


#CLT and t-distribution in Practice Exercises #3
#1 point possible (graded)
#As we have already seen, the CLT also applies to averages of quantitative data. A major difference with binary data, for which we know the variance is , is that with quantitative data we need to estimate the population standard deviation.

#In several previous exercises we have illustrated statistical concepts with the unrealistic situation of having access to the entire population. In practice, we do *not* have access to entire populations. Instead, we obtain one random sample and need to reach conclusions analyzing that data. dat is an example of a typical simple dataset representing just one sample. We have 12 measurements for each of two populations:


```{r}
df = dat[dat$Diet =="chow",]
X = df$Bodyweight
df1 = dat[dat$Diet =="hf",]
Y = df1$Bodyweight

mean(X) #23.81333
```

#CLT and t-distribution in Practice Exercises #4
#1/1 point (graded)
#We don't know, but want to use  to understand . Which of the following uses CLT to understand how well approximates?

Solution: X.bar follows a normal distribution with mean mew_x and standard deviation sigma_x/sqrt(12) where sigmax is the population standard deviation.


#CLT and t-distribution in Practice Exercises #5
#1/1 point (graded)
#The result above tells us the distribution of the following random variable: sqrt(12) (x.bar-mew_x)/sigmax. What does the CLT tell us is the mean of  (you don't need code)?


Solution: 0

#CLT and t-distribution in Practice Exercises #6
#1 point possible (graded)
#The result of 4 and 5 tell us that we know the distribution of the difference between our estimate and what we want to estimate, but don't know. However, the equation involves the population standard deviation , which we don't know.
#Given what we discussed, what is your estimate of sigma_x?

```{r}
library(rafalib)
sd(X) #3.022541, Note this is sample standard derivation for x.
```

#CLT and t-distribution in Practice Exercises #7
#1 point possible (graded)
#Use the CLT to approximate the probability that our estimate  is off by more than 2 grams from mu_x.
```{r}
Z <- sqrt(12)*( X - mean(X) ) / popsd(X)
mean( abs(Z) >2 ) #0.6950673

#Solution
2 * ( 1-pnorm(2/sd(X) * sqrt(12) ) ) # 0.02189533
```



#CLT and t-distribution in Practice Exercises #8
#1 point possible (graded)
#Now we introduce the concept of a null hypothesis. We don't know mewx nor mewy. We want to quantify what the data say about the possibility that the diet has no effect: mewx = mewy. If we use CLT, then we approximate the distribution of X.bar as normal with mean mewx and standard deviation sigmax/sqrt(M) and the distribution of Y.bar as normal with mean mewy  and standard deviation sigmay/sqrt(N), with M and N the sample sizes for X and Y respectively, in this case 12. This implies that the difference Y.bar-X.bar has mean 0. We described that the standard deviation of this statistic (the standard error) is SE(X.bar-Y.bar)= sqrt(sigmay^2/12 + sigmax^2/12) and that we estimate the population standard deviations  and  with the sample estimates.

solution:
```{r}
s = sqrt(sd(Y)^2/12 + sd(X)^2/12)# 1.469867
s
```

#CLT and t-distribution in Practice Exercises #9
#1 point possible (graded)
#So now we can compute  as well as an estimate of this standard error and construct a t-statistic. What number is this t-statistic?
```{r}
#T-Statistic 
t = (mean(X)-mean(Y))/s
abs(t) #2.055174

```

#CLT and t-distribution in Practice Exercises #10
#0/1 point (graded)
#If we apply the CLT, what is the distribution of this t-statistic?
Solution: Normal with mean 0 and standard deviation 1.

#CLT and t-distribution in Practice Exercises #11
#1 point possible (graded)
#Now we are ready to compute a p-value using the CLT. What is the probability of observing a quantity as large as what we computed in 9, when the null distribution is true?
```{r}
pt(q=abs(t),df=24,lower.tail = TRUE)

#
Z <- ( mean(Y) - mean(X) ) / sqrt( var(X)/12 + var(Y)/12)
2*( 1-pnorm(Z))

```

#CLT and t-distribution in Practice Exercises #12
#1 point possible (graded)
#CLT provides an approximation for cases in which the sample size is large. In practice, we can't check the assumption because we only get to see 1 outcome (which you computed above). As a result, if this approximation is off, so is our p-value. As described earlier, there is another approach that does not require a large sample size, but rather that the distribution of the population is approximately normal. We don't get to see this distribution so it is again an assumption, although we can look at the distribution of the sample with qqnorm(X) and qqnorm(Y). If we are willing to assume this, then it follows that the t-statistic follows the t-distribution.

#What is the p-value under the t-distribution approximation?
```{r}
qqnorm(X)
```


```{r}
qqnorm(Y)
```











```{r}
t.test(X,Y,alternative = c("two.sided"), mu=0,paired=FALSE,var.equal = FALSE,conf.level=0.95) #0.053
```

#CLT and t-distribution in Practice Exercises #13
#1/1 point (graded)
#With the CLT distribution, we obtained a p-value smaller than 0.05 and with the t-distribution, one that is larger. They can't both be right. What best describes the difference?

Solution: These are two different assumptions. The t-distribution accounts for the variability introduced by the estimation of the standard error and thus, under the null, large values are more probable under the null distribution.

#Week 2 Quiz
#Question 1
```{r}
RNGkind("Mersenne-Twister", "Inversion", "Rejection")
```

#When we studied null distributions, you may have noticed that the answers to questions 1 and 2 barely changed. This is expected. The way we think about the random value distributions is as the distribution of the list of values obtained if we repeated the experiment an infinite number of times. On a computer, we can't perform an infinite number of iterations, so instead, for our examples, we consider 1,000 to be large enough. Now if instead we change the sample size, then we change the random variable and thus its distribution.

#Reload the data set from that section:



```{r}
library(downloader) 
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleControlsPopulation.csv"
filename <- basename(url)
download(url, destfile=filename)
x <- unlist( read.csv(filename) )
```
#Set the seed at 1, then using a for-loop take a random sample of 50 mice 1,000 times. Save these averages.

#What proportion of these 1,000 averages are more than 1 gram away from the average of x?
```{r}
set.seed(1)
n <- 1000
averages50 <- vector("numeric",n)
for(i in 1:n){
  X <- sample(x,50)
  averages50[i] <- mean(X)
}
hist(averages50) ##take a look
mean( abs( averages50 - mean(x) ) > 1) #0.014

```


#Question #2
#1 point possible (graded)
#Reload the gapminder data:
```{r}
library(gapminder)
data(gapminder)
head(gapminder)
```


#What is the proportion of countries in 1952 that have a life expectancy between 40 and 60 years?

#Hint: this is the proportion that have a life expectancy less than or equal to 60 years, minus the proportion that have a life expectancy less than or equal to 40 years.

```{r}
dat1952 = gapminder[gapminder$year == 1952, ]
x = dat1952$lifeExp
mean(x<60&x>40) # 0.4647887

```

#Question #3
#1/1 point (graded)
#When we examined mouse weights, we found that our sample estimates for females were closer to the population difference than with males. What is a possible explanation for this?

Solution: The population variance of the females is smaller than that of the males; thus, the sample variable has less variability.


#Question #4
#0/1 point (graded)
#Create qq-plots for the four populations: male/females on each of the two diets. What is the best explanation for all these mouse weights being well approximated by the normal distribution?

```{r}
library(rafalib)
a = dat1
b = a[a$Sex=='M'&a$Diet=='chow',]
Mchow = b$Bodyweight
z =( Mchow - mean(Mchow) ) / popsd(Mchow)
qqnorm(z);abline(0,1)

```

```{r}
library(rafalib)
a = dat1
c = a[a$Sex=='F'&a$Diet=='chow',]
Fchow = b$Bodyweight
z2 =( Fchow - mean(Fchow) ) / popsd(Fchow)
qqnorm(z2);abline(0,1)

```

```{r}
library(rafalib)
a = dat1
d = a[a$Sex=='M'&a$Diet=='hf',]
Mhf = d$Bodyweight
z3 =( Mhf - mean(Mhf) ) / popsd(Mhf)
qqnorm(z3);abline(0,1)

```
```{r}
library(rafalib)
a = dat1
e = a[a$Sex=='F'&a$Diet=='hf',]
Fhf = e$Bodyweight
z4 =( Fhf - mean(Fhf) ) / popsd(Fhf)
qqnorm(z4);abline(0,1)

```

Solution: This just happens to be how nature behaves in this particular case. Perhaps the result of many biological factors averaging out.
